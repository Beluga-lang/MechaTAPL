\chapter{Introduction}

A formal definition of a programming language
provides a precise specification not only for programmers, but also
for implementors of these languages. Working with formal definitions such as the
ones we have explored so far is often easier when we can animate their use using
a concrete implementation. This allows us to gain a deeper understanding of the
systems we are working with.

However, formal definitions not only provide a precise spec for implementors,
but allows the rigorous analysis of its properties such as uniqueness of
evaluation, or type safety. But a language definition is also an
intricate artifact, which is carefully designed, and the proof of its
properties are often complex and subtle --  above all many cases are
tedious. How then can we trust our language design? How can we trust
that indeed the properties we claim about a language are true? How do
we know that a given program indeed satisfies a certain safety
property? How can we compare different properties? --  
%
Realistic languages have many cases to be considered, and while many
of them will be straightforward, the task of verifying them all can
be complex. Consequently it can be difficult to define a language
correctly, and prove the appropriate theorems -- let alone maintain
the definition and the associated proofs when the language evolves and
changes.  

Fortunately, the burden can be alleviated by mechanizing the
definition of a language together with its meta-theory. In this companion,
we will give a brief introduction to the logical framework LF \citep{Harper93jacm} and its
implementation in Beluga \citep{Pientka:POPL08,Pientka:PPDP08,Pientka:IJCAR10,Cave:POPL12} -- a programming environment which
supports the implementation of language definitions and their
meta-theory. It supports the definition of formal systems given via
axioms and inference rules, as well as proofs about these formal
systems. It is an ideal environment to prototype languages and explore their
theoretical properties. %Compared to other existing approaches, Beluga provides the most infrastructure


\section{Mechanizing Definitions} Language formalization frequently
start an informal, on-paper definition of the language. It mostly
consists of 3 distinct parts: 

\begin{itemize}
\item Represent the grammar / syntax of a language
\item Represent its operational and static semantic
\item Represent its meta-theory, i.e. proofs about the semantics such
  type preservation and progress, correctness of program transformations, and normalization.
\end{itemize}

Each layer brings up different questions we must address. The choice
we make in each of the questions substantially influences how easy it
is to attack the next layer.  There are a number of systems we could have chosen to mechanize each layer such as Coq or Isabelle. In these notes we use system that is specialized for our task and provides the most supporting infrastructure. 
 

\section{Adequacy} An important question we must keep in mind in
this endeavour is the following: 
What does it mean to correctly represent such a language
definition in a formal framework? -- In general, we aim for a
\emph{adequate representation}, i.e. the objects represented formally
in the framework describe exactly those we were talking about on
paper. More precisely, the representation of the language is
isomorphic to the informal definition of the language we had on
paper. But in practice we even want more: we want that the structure
of the language is preserved as well -- this will mean that we want a
bijection (in fact a compositional bijection).

% To establish adequacy, we require two tools: 1) Adequacy proof:
% induction proofs on the canonical forms of LF 2) Modularity of
% adequacy proofs based on subordination (we must understand under what
% assumptions/circumstances is an encoding adequate and when it is
% adequate with respect to one set of assumptions, how do we know it
% remains adequate given some other set of assumptions)

Adequacy is a deep property of an encoding and maybe surprisingly it
is a property that often does not hold. In fact, often our
representation in some programming / proof environment admits many
more terms than are meaningful. 

We omit here a detailed discussion of how to prove adequacy, we
will refer the interested reader to the article
\citep{HarperLicata:JFP07}. 