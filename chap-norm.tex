\chapter{Normalization}\label{chap:normalization}

In Chapter~\ref{chap:binders}, we discussed the Simply Typed Lambda
Calculus (STLC), its grammar, operational semantics and typing
judgement.  In addition, we studied some meta-theoretic properties of
this formalism such as type preservation, the fact that type is
preserved under evaluation of the operational semantics, and type
uniqueness, the fact that each well-typed term has only one type. In
this chapter we will explore another meta-theoretical property,
normalization --i.e., the evaluation of well-typed terms always
terminates. We proved earlier in Section \ref{sec:termination}
termination of evaluation for a simple language containing arithmetic
and booleans. This proof was straightforward by structural induction
on the typing derivation. Unfortunately, proving this property for the
simply typed lambda-calculus is more challenging. A direct proof via
structural induction fails. Instead, we fall back to a technique
called proofs by logical relations going back to Tait  \cite{Tait67}
and was later refined by Girard
\citep{GirardLafontTaylor:proofsAndTypes}. The central idea of logical
relations is to specify relations on well-typed terms via structural
induction on the syntax of types instead of directly on the syntax of
terms themselves. Thus, for instance, logically related functions take
logically related arguments to related results, while  logically
related pairs consist of components that are related pairwise.

Mechanizing logical relations proofs is challenging: first, specifying logical relations themselves typically requires a logic which allows arbitrary nesting of quantification and implications; second, to establish soundness of a logical relation, one must prove the Fundamental Property which says that any well-typed term under a closing simultaneous substitution is in the relation. This latter part requires some notion of simultaneous substitution together with the appropriate equational theory of composing substitutions. As Altenkirch \cite{Altenkirch:TLCA93} remarked,

\begin{quote}
``I discovered that the core part of the proof (here proving lemmas about CR) is fairly straightforward and only requires a good understanding of the paper version. However, in completing the proof I observed that in certain places I had to invest much more work than expected, e.g. proving lemmas about substitution and weakening.''
\end{quote}

While logical normalization proofs often are not large, they are
conceptually intricate and mechanizing them has become a challenging
benchmark for proof environments. In \beluga, this proof and similar
logical relations proofs can be implemented concisely. In developing
this kind of proof in \beluga, we introduce several new ideas:

\begin{itemize}
\item We will start by revisiting well-typed lambda-terms together with a
simple call-by-name semantics and show an intrinsically.

\item Using inductive definitions to define reducibility candidates
  and other properties of derivations and contexts

\item Using first-class substitution variables

\end{itemize}





\section{Representing Well-Typed Terms}

Let's revisit the definition of STLC, starting with the grammar of terms, values and types:

\[
\begin{array}{ll@{\bnfas}l}
\mbox{Terms} & M, N & x \bnfalt \lam x.M \bnfalt M \app N \bnfalt c\\
\mbox{Types} & T, S & B \bnfalt T \arrow S\\
\mbox{Values} & V & \lam x{:}T.M \bnfalt c
\end{array}
\]

Please note that in this presentation, we added to the language base
type and a constant term.

Then we define the small-step operational semantics. In this
particular presentation we use rules are different to
chapter~\ref{chap:binders}. This presentation corresponds to what is
typically referred to as a Call-By-Name operational semantics.

\[
\begin{array}{c}
\multicolumn{1}{l}{\fbox{$M \Steps M'$}: \mbox{Term $M$ steps to term $M'$}}
\\[1em]
\infer[\EAppBeta]{(\lam x.M) \app N \Steps [N/x]M}{} \qquad
\infer[\EAppArgStep]{M \app N \Steps M'\;N}{M \Steps M'} \\[1em]
% \infer[\EAppFnStep]{V \app N \Steps V\;N'}{N \Steps N' & V \Value}
\end{array}
\]

Finally, we define the typing judgement. Note that we added the rule
\TBase for the new type and term.

\[
\begin{array}{c@{\qquad}c}
\multicolumn{2}{l}{\mbox{Typing rules \fbox{$M:T$}}} \\[1em]
\infer[\TFn^{x,u}]{\lam x.M : T \arrow S}
                 {\infer*{M:S}{\infer[u]{x:T}{}}} &
\infer[\TApp]{M\;N : S}{M : T \arrow S & N:T} \\[1em]
\multicolumn{2}{c}{\infer[\TBase]{c : B}{}}
\end{array}
\]

In Chapter~\ref{chap:binders}, the formalization in Beluga followed
very closely the paper presentation, in this case we will take a
slightly different approach in which we combine the syntax of terms
and the typing rules to obtain and \emph{intrinsically typed
  representation} of the language.

%\begin{extract}[norm.bel]
\begin{lstlisting}
LF tp : type =
| b :  tp
| arr : tp -> tp -> tp
;

LF tm : tp -> type =
| app : tm (arr T S) -> tm T -> tm S
| lam : (tm T -> tm S) -> tm (arr T S)
| c : tm b
;
\end{lstlisting}
%\end{extract}

The type \bel{tm} defines our family of simply-typed lambda terms
indexed by their type as an LF signature. In typical higher-order
abstract syntax (HOAS) fashion, lambda abstraction takes a function
representing the abstraction of a term over a variable. There is no
case for variables, as they are treated implicitly in HOAS.

We now encode the step relation of the operational semantics. In
particular, we create the \bel{step} type indexed by two terms that
represent each step of the computation.

\begin{lstlisting}
LF step : tm A -> tm A -> type =
| beta : step (app (lam M) N) (M N)
| stepapp : step M M' -> step (app M N) (app M' N)
;
\end{lstlisting}

Notice how the \bel{beta} rule re-uses the LF notion of substitution by
computing the application of \bel{M} to \bel{N}.

Finally, because we want to prove that every chain of evaluation steps
terminates, we need to define:
\begin{itemize}
\item a multiple step reduction \bel{mstep}.
\item values \bel{val}
\item and \bel{halts} to encode that a term halts if it steps into a value.
\end{itemize}

\begin{lstlisting}
LF mstep : tm A -> tm A -> type =
| refl : mstep M M
| onestep : step M M' -> mstep M' M'' -> mstep M M''
;
\end{lstlisting}

In \bel{mstep} we say that every term steps to itself, and that you can
always add another small-step to a chain of steps.

\begin{lstlisting}
LF val : tm A -> type =
| val/c : val c
| val/lam : val (lam M)
;
%name val V.
\end{lstlisting}

To characterize values, instead of directly implementing the grammar
of values, we define a predicate on well-typed terms that selects the
values.

\begin{lstlisting}
LF halts : tm A -> type =
| halts/m : mstep M M' -> val M' -> halts M
;
%name halts H.
\end{lstlisting}

Finally, \bel{halts} is also a predicate on terms, and only terms that
eventually step into a value are in it. Thus, the proof of
normalization needs to establish that all terms are in \bel{halts}. At
this point, one might be tempted to prove this by induction on the
structure of terms. However, the na\"if approach fails here because
the induction hypothesis we get is not strong
enough. \improvement{Perhaps one could add an exercise as in TAPL for this}

\section{Proving Normalization}

In order to have an induction hypothesis that is strong enough we need
to define an inductive predicate on types that specifies what terms
can be candidates to be reducible.

We define the \emph{Reducibility Candidates} predicate as:

\begin{itemize}
\item \rc \iota B iff $M$ halts
\item \rc{T\arrow S} M iff $M$ halts and for all $N$, if \rc {T} N then \rc{S}{M\app N}
\end{itemize}

The definitions states that a term of base type is in the relation if
it halts, and a term of function type when it halts and it is well
behaved under application. The general idea of the proof is to show
that the terms in \rc{T}{M} have the desired property and then we need
to prove that all terms are reducible. In this case the desired
property is that the evaluation of the term halts, and it straight
forward to show that if a term is reducible then its evaluation halts.

Reducibility cannot be directly encoded at the LF layer, since it
involves a strong, computational function space. Hence we move to the
computation layer of Beluga, and employ an indexed recursive
type. Contextual LF objects and contexts which are embedded into
computation-level types and programs are written inside \bel{[ ]}.

\begin{lstlisting}
stratified Reduce : {A:[|- tp]}{M:[|- tm A]} ctype =
| Rb : [|- halts M] -> Reduce [|- b ] [|- M]
| Rarr :  [|- halts M] ->
    ({N:[|- tm A]} Reduce [|- A ] [|- N] -> Reduce [|- B ] [|- app M N])
    -> Reduce [|- arr A B ] [|- M]
;
\end{lstlisting}

A term of type \bel{b} is reducible if it halts, and a \bel{term M} of type
\bel{arr A B} is reducible if it halts, and moreover for every reducible
\bel{N} of type \bel{A}, the application \bel{app M N} is reducible. We write
\lstinline!{N:[|-tm A]}! for explicit $\Pi$-quantification over \bel{N}, a closed term
of type \bel{A}. To the left of the turnstile in \bel{[|- tm A]} is where one
writes the context the term is defined in -- in this case, it is empty.

In this definition, the arrows represent the usual computational
function space, not the weak function space of LF. We note that this
definition is not (strictly) positive, since \bel{Reduce} appears to the
left of an arrow in the \bel{Rarr} case. Allowing unrestricted such
definitions destroys the soundness of our system. Here we note that
this definition is stratified by the type: the recursive occurrences
of \bel{Reduce} are at types \bel{A} and \bel{B} which are smaller than \bel{arr A B}.
\bel{Reduce} is defined by induction on the type of the reducible
term(additionally this is why we cannot leave the type implicit).

Now, we need to prove some more or less trivial lemmas that are
some times omitted in paper presentations.

First, we prove that halts is closed under expansion in the \bel{halts_step} lemma.

\begin{lstlisting}
rec halts_step : {S:[|- step M M']} [|- halts M'] -> [|- halts M] =
mlam S => fn h =>
let [|- halts/m MS' V] = h in
 [|- halts/m (onestep S MS') V]
;
\end{lstlisting}

Next we prove closure of Reduce under expansion. This follows by
induction on the type \bel{A}' which is an implicit argument. In the
base case we appeal to \bel{halts_step}, while in the \bel{Rarr} case
we must also appeal to the induction hypothesis at the range type,
going inside the function position of applications.

\begin{lstlisting}
rec bwd_closed : {S:[|- step M M']} Reduce [|- T] [|- M'] -> Reduce [|- T] [|- M] =
mlam MS => fn r => case r of
| Rb ha => Rb (halts_step [|- MS] ha)
| Rarr ha f => Rarr (halts_step [|- MS] ha)
  (mlam N => fn rn =>
   bwd_closed [|- stepapp MS] (f [|- N] rn))
;
\end{lstlisting}

The trivial fact that reducible terms halt has a corresponding
trivial proof, analyzing the construction of the the proof of
\bel{Reduce[|- T] [|- M]}

\begin{lstlisting}
rec reduce_halts : Reduce [|- T] [|- M] -> [|- halts M] =
fn r => case r of
| Rb h => h
| Rarr h f => h
;
\end{lstlisting}

It is at this point, that we may start thinking on the proof of the
main theorem. The main theorem states that all terms are reducible, so
a first approximation to this could be to try to prove this theorem:

\begin{lstlisting}
rec main : {M:[|- tm A[]]} Reduce [|- A] [|- M] =
  ?
;
\end{lstlisting}

However, if we try to prove this theorem, we very quickly realize that
we need to have appeals to the induction hypothesis for open term. In
particular, when trying to build the reducibility candidate for
$\lambda$-terms.

\subsection{Reducibility of substitutions}

As motivated by the previous section, we need to be able to talk about
open terms, fortunately Beluga has first class support for open
terms. The first thing we need is declaration of a schema, that is a
classifier of contexts.

For our normalization proof, we needs contexts that contain well-typed
terms, as open terms have only terms as assumptions. So we declare a schema:
\begin{lstlisting}
schema ctx = tm T;
\end{lstlisting}

Also, to  we need the concept of \emph{grounding substitutions}, again
natively supported in Beluga as substitution from some context into an
empty context. And we need also to define what it means for a
substitution to be \emph{reducible}. In particular, a \emph{a
  reducible substitution} is a substitution where all the terms that
compose it are also reducible. We define that, using an inductive
data-type indexed by grounding substitutions.

\begin{lstlisting}
inductive RedSub : {g:ctx}{#S:[|- g]} ctype =
| Nil : RedSub  [ ] [|- ^ ]
| Dot : RedSub  [g] [|- #S[^] ] -> Reduce [|- A] [|- M]
     -> RedSub [g, x:tm A[]] [|- #S,M ]
;

rec lookup : {g:ctx}{#p:[g |- tm A[]]}RedSub [g] [|- #S[^]] ->
             Reduce [|- A] [|- #p[#S[^]]] =
mlam g => mlam #p => fn rs => case [g |- #p[..]] of
 | [g',x:tm A |-  x] =>    let (Dot rs' rN) = rs in rN
 | [g',x:tm A |-  #q[..]] => let Dot rs' rN = rs in
                      lookup [g'] [g' |-  #q[..]] rs'
;
\end{lstlisting}

We also show how to look-up a reducible term in a reducible
substitution by using the \bel{lookup} function.

Now, we have all the elements in place, so we can proceed to prove the
main lemma, generalizing all terms under reducible grounding substitutions are
in the \bel{Reduce} relation.
\begin{lstlisting}
rec main : {g:ctx}{M:[g |- tm A[]]} RedSub [g] [|- #S[^]] ->
           Reduce [|- A] [|- M[#S[^]]] =
 mlam g => mlam M => fn rs => case [g |- M[..]] of
| [g |- #p[..]] => lookup [g] [g |- #p[..]] rs
| [g |- lam (\x. M1)] =>
 Rarr [|- halts/m refl val/lam]
   (mlam N => fn rN =>
    bwd_closed [|- beta] (main [g,x:tm _] [g,x |- M1] (Dot rs rN)))
 | [g |- app (M1[..]) (M2[..])] =>
  let Rarr ha f = main [g] [g |- M1[..]] rs in
  f [|- _ ] (main [g] [g |- M2[..]] rs)
| [g' |-  c] => Rb [|- halts/m refl val/c]
;
\end{lstlisting}

And finally we have all the elements to prove that all well typed
terms eventually reduce to a value:
\begin{lstlisting}
rec weakNorm : {M:[|- tm A]} [|- halts M] =
mlam M => reduce_halts (main [] [|- M] Nil)
;
\end{lstlisting}

Let's retrace our steps. We set out to prove that all terms reduce into a
value. A simple proof by induction would not give us a powerful enough
induction hypothesis, so we defined the reducibility candidate
relation that was inductive on the type and allowed for a powerful enough
induction hypothesis. Then when proving that all terms are reducibl, We needed again a more powerful induction
hypothesis to be able to prove that all terms were in the reducibility
relation. In particular, we generalized the theorem to all terms and
their grounding substitutions, for this we needed a predicate on
grounding substitution, to be sure that all the terms in them were
reducible. With all this machinery in place the proof went through by
appealing to the lemmas we had proven earlier.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "book"
%%% End:
